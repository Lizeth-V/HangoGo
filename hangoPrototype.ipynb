{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e658ea-3a2a-40ac-b98a-2c41a6022902",
   "metadata": {},
   "source": [
    "**This Is The prototype code for our Neural Network code**\n",
    "\n",
    "***its coded in python using tensor flow in jupyter notebook to maintain data integrity***\n",
    "\n",
    "Can be put into a python file, but needs lots of setup on the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b445dea0-9efd-4ce8-acd0-06e30ca79f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>address</th>\n",
       "      <th>main_type</th>\n",
       "      <th>sub_types</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_amount</th>\n",
       "      <th>age</th>\n",
       "      <th>price</th>\n",
       "      <th>weblink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65c7c805d20df83fcf08aa6b</td>\n",
       "      <td>The Great White Hut</td>\n",
       "      <td>34.150018</td>\n",
       "      <td>-118.256291</td>\n",
       "      <td>121 W California Ave, Glendale</td>\n",
       "      <td>Food</td>\n",
       "      <td>[restaurant, food]</td>\n",
       "      <td>4.2</td>\n",
       "      <td>818</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.google.com/maps/place/?q=place_id:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65c7c805d20df83fcf08aa6c</td>\n",
       "      <td>Chick-fil-A</td>\n",
       "      <td>34.049347</td>\n",
       "      <td>-118.259377</td>\n",
       "      <td>660 S Figueroa St, Los Angeles</td>\n",
       "      <td>Food</td>\n",
       "      <td>[restaurant, food]</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1840</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.google.com/maps/place/?q=place_id:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65c7c805d20df83fcf08aa6d</td>\n",
       "      <td>Melrose Food Co - by CloudKitchens</td>\n",
       "      <td>34.082243</td>\n",
       "      <td>-118.309399</td>\n",
       "      <td>615 N Western Ave, Los Angeles</td>\n",
       "      <td>Food</td>\n",
       "      <td>[restaurant, food]</td>\n",
       "      <td>4.5</td>\n",
       "      <td>133</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.google.com/maps/place/?q=place_id:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65c7c805d20df83fcf08aa6e</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>34.003267</td>\n",
       "      <td>-118.406905</td>\n",
       "      <td>4416 Sepulveda Blvd, Culver City</td>\n",
       "      <td>Food</td>\n",
       "      <td>[meal_takeaway, restaurant, food]</td>\n",
       "      <td>3.9</td>\n",
       "      <td>618</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.google.com/maps/place/?q=place_id:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65c7c805d20df83fcf08aa6f</td>\n",
       "      <td>Grand Food Depot</td>\n",
       "      <td>34.014740</td>\n",
       "      <td>-118.278774</td>\n",
       "      <td>358 W 38th St, Los Angeles</td>\n",
       "      <td>Food</td>\n",
       "      <td>[restaurant, food]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>258</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.google.com/maps/place/?q=place_id:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   place_id                                name        lat  \\\n",
       "0  65c7c805d20df83fcf08aa6b                 The Great White Hut  34.150018   \n",
       "1  65c7c805d20df83fcf08aa6c                         Chick-fil-A  34.049347   \n",
       "2  65c7c805d20df83fcf08aa6d  Melrose Food Co - by CloudKitchens  34.082243   \n",
       "3  65c7c805d20df83fcf08aa6e                           Taco Bell  34.003267   \n",
       "4  65c7c805d20df83fcf08aa6f                    Grand Food Depot  34.014740   \n",
       "\n",
       "          lon                           address main_type  \\\n",
       "0 -118.256291    121 W California Ave, Glendale      Food   \n",
       "1 -118.259377    660 S Figueroa St, Los Angeles      Food   \n",
       "2 -118.309399    615 N Western Ave, Los Angeles      Food   \n",
       "3 -118.406905  4416 Sepulveda Blvd, Culver City      Food   \n",
       "4 -118.278774        358 W 38th St, Los Angeles      Food   \n",
       "\n",
       "                           sub_types  rating  rating_amount age price  \\\n",
       "0                 [restaurant, food]     4.2            818   N     1   \n",
       "1                 [restaurant, food]     4.2           1840   N     1   \n",
       "2                 [restaurant, food]     4.5            133   N     2   \n",
       "3  [meal_takeaway, restaurant, food]     3.9            618   N     1   \n",
       "4                 [restaurant, food]     4.6            258   N     2   \n",
       "\n",
       "                                             weblink  \n",
       "0  https://www.google.com/maps/place/?q=place_id:...  \n",
       "1  https://www.google.com/maps/place/?q=place_id:...  \n",
       "2  https://www.google.com/maps/place/?q=place_id:...  \n",
       "3  https://www.google.com/maps/place/?q=place_id:...  \n",
       "4  https://www.google.com/maps/place/?q=place_id:...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#install all of these dependencies, \n",
    "#tensorflow however required me to change some paths in my windows machine\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.utils import FeatureSpace\n",
    "import random\n",
    "\n",
    "#read in dataframe from the cleaned datafile\n",
    "place_df = pd.read_json('Hango.Places.json')\n",
    "\n",
    "#where Nhu's subtype coding will go\n",
    "\n",
    "place_df.rename(columns={'_id': 'place_id'}, inplace=True)\n",
    "\n",
    "place_df['place_id'] = place_df['place_id'].apply(lambda x: x['$oid'])\n",
    "\n",
    "place_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2b38a7d-27da-4350-a676-7685b57e1843",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['place_id', 'name', 'lat', 'lon', 'address', 'rating', 'rating_amount',\n",
      "       'age', 'price', 'weblink',\n",
      "       ...\n",
      "       'trainers', 'videos_&_video_game_rental', 'diners', 'ramen',\n",
      "       'main_type_Drinks', 'main_type_Entertainment', 'main_type_Food',\n",
      "       'main_type_Museum/Art', 'main_type_Nature/Recreation',\n",
      "       'main_type_Nightlife'],\n",
      "      dtype='object', length=372)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Get unique subtypes\n",
    "unique_subtypes = set(subtype for sublist in place_df['sub_types'] for subtype in sublist)\n",
    "\n",
    "# Create a DataFrame with one-hot encoding columns for subtypes\n",
    "subtype_df = pd.DataFrame({subtype: place_df['sub_types'].apply(lambda x: 1 if subtype in x else 0) for subtype in unique_subtypes})\n",
    "\n",
    "# Concatenate the original DataFrame with the new subtype DataFrame\n",
    "place_df = pd.concat([place_df, subtype_df], axis=1)\n",
    "\n",
    "# Apply one-hot encoding to 'main_type' column\n",
    "place_df = pd.get_dummies(place_df, columns=['main_type'], prefix='main_type')\n",
    "\n",
    "# Drop the original 'sub_types' column if needed\n",
    "place_df = place_df.drop('sub_types', axis=1)\n",
    "#place_df = place_df.drop('main_type', axis=1)\n",
    "\n",
    "#place_df['age'] = place_df_features['age'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "place_df.head()\n",
    "place_df.shape\n",
    "print(place_df.columns)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9419e8a0-389e-4b1b-bddc-e41c724fb324",
   "metadata": {
    "tags": []
   },
   "source": [
    "userdata ={\n",
    "  \"_id\": {\n",
    "    \"$oid\": \"6567dcefba91df16f20f718d\"\n",
    "  },\n",
    "  \"username\": \"john_doe\",\n",
    "  \"full_name\": \"John Doe\",\n",
    "  \"email\": \"john@example.com\",\n",
    "  \"age\": 30,\n",
    "  \"address\": {\n",
    "    \"street\": \"123 Main St\",\n",
    "    \"city\": \"Anytown\",\n",
    "    \"state\": \"CA\",\n",
    "    \"zip_code\": \"12345\",\n",
    "    \"country\": \"USA\"\n",
    "  }\n",
    "}\n",
    "\n",
    "#This is a function that builds fake reviews.\n",
    "#We have no data due to a cold start so we need to create artificial feedback\n",
    "def generateFakeReviews(id,age):\n",
    "    \n",
    "    reviewTable = pd.DataFrame()\n",
    "\n",
    "    #This chooses 100 random places to give positive implicit feedback\n",
    "    #Put into a temporary table\n",
    "\n",
    "    #Change k to change amount\n",
    "    positive_choices = random.sample(place_df['place_id'].tolist(), k=50)\n",
    "    positive_reviews = [{'user_id': id, 'u_age': age, 'place': place, 'feedback': 1} for place in positive_choices]\n",
    "    \n",
    "    #This chooses 75 random places to give negative implicit feedback\n",
    "    #Put into a temporary table\n",
    "\n",
    "    #Change k to change amount\n",
    "    negative_choices = random.sample(place_df['place_id'].tolist(), k=50)\n",
    "    negative_reviews = [{'user_id': id, 'u_age': age, 'place': place, 'feedback': 0} for place in negative_choices]\n",
    "    \n",
    "    #append both to the temporary review table and return it\n",
    "    reviewTable = reviewTable.append(positive_reviews, ignore_index=True)\n",
    "    reviewTable = reviewTable.append(negative_reviews, ignore_index=True)\n",
    "\n",
    "    return reviewTable\n",
    "\n",
    "# Example usage\n",
    "#age = 25 Need to figure out how this can help in content based filtering\n",
    "\n",
    "#temp user id for programming and testing\n",
    "uid = '6567dcefba91df16f20f718d'\n",
    "\n",
    "#generate the fake review table\n",
    "#keep age in it for now\n",
    "generated_reviews = generateFakeReviews(id=uid, age=25)\n",
    "\n",
    "generated_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f90788a-ae90-4cc1-b2b5-0a3925eee06a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         _id                  place_id  \\\n",
      "0   65d7c81af96a790754860479  65c7cd4d7f987a416ea45ab1   \n",
      "1   65d7c7e1f96a790754850e65  65c7cd617f987a416ea45c8b   \n",
      "2   65d7c795f96a79075483b907  65c7cd627f987a416ea45c98   \n",
      "3   65d7c7a7f96a790754841284  65c7cd637f987a416ea45ca7   \n",
      "4   65d7c7bff96a790754847da4  65c7cd757f987a416ea45e6c   \n",
      "5   65d7c7abf96a790754842452  65c7cd767f987a416ea45e71   \n",
      "6   65d7c833f96a7907548675e5  65c7cd767f987a416ea45e85   \n",
      "7   65d7c48df96a79075475433f  65c7cd887f987a416ea46035   \n",
      "8   65d7c790f96a790754839e3d  65c7cd9a7f987a416ea461f5   \n",
      "9   65d7c826f96a790754863ecf  65c7cd9b7f987a416ea461f9   \n",
      "10  65d7c82af96a790754864fee  65c7cd9b7f987a416ea46206   \n",
      "11  65d7c79bf96a79075483d6d9  65c7cdad7f987a416ea463b8   \n",
      "12  65d7c7fdf96a79075485890e  65c7cdae7f987a416ea463c5   \n",
      "13  65d7c7c7f96a790754849d21  65c7cdae7f987a416ea463c6   \n",
      "14  65d7c7d4f96a79075484d829  65c7cdaf7f987a416ea463d6   \n",
      "15  65d7c7bdf96a790754847459  65c7cdaf7f987a416ea463d7   \n",
      "16  65d7c7d7f96a79075484e129  65c7cdaf7f987a416ea463d9   \n",
      "17  65d7c805f96a79075485a73e  65cbbda0e88f8c2f795c975e   \n",
      "18  65d7c80af96a79075485be30  65cbc26ac72cccdf7a645431   \n",
      "19  65d7c7e8f96a790754852c3d  65cbc26ac72cccdf7a645432   \n",
      "20  65d7c7cdf96a79075484b56d  65cbc26ac72cccdf7a645434   \n",
      "21  65d7c798f96a79075483c8e2  65cbc26bc72cccdf7a645440   \n",
      "22  65d7c7eef96a790754854787  65cbc26bc72cccdf7a645441   \n",
      "23  65d7c7e6f96a7907548523b4  65cbc26bc72cccdf7a645445   \n",
      "24  65d7c7b5f96a790754845493  65cbc26bc72cccdf7a64544b   \n",
      "25  65d7c815f96a79075485eb4f  65cbc26bc72cccdf7a64544d   \n",
      "26  65d7c7bbf96a790754846c34  65cbc27dc72cccdf7a645611   \n",
      "27  65d7c81ef96a7907548616e0  65cbc27dc72cccdf7a64561a   \n",
      "28  65d7c7d3f96a79075484cf99  65cbc27dc72cccdf7a645622   \n",
      "29  65d7c82df96a790754865d39  65cbc27ec72cccdf7a64562a   \n",
      "30  65d7c7eaf96a7907548537b1  65cbc27ec72cccdf7a64562c   \n",
      "31  65d7c817f96a79075485f4cc  65cbc27ec72cccdf7a64562e   \n",
      "32  65d7c7b2f96a79075484458e  65cbc27ec72cccdf7a645630   \n",
      "33  65d7c7f1f96a7907548552b5  65cbc2b5c72cccdf7a645bea   \n",
      "34  65d7c7c1f96a79075484876e  65cbc2b5c72cccdf7a645bee   \n",
      "35  65d7c812f96a79075485e142  65cbc2b5c72cccdf7a645bf5   \n",
      "36  65d7c807f96a79075485b02c  65cbc2b6c72cccdf7a645bf7   \n",
      "37  65d7c82ff96a7907548667bc  65cbc2b6c72cccdf7a645c00   \n",
      "38  65d7c7dcf96a79075484f823  65cbc2b6c72cccdf7a645c0f   \n",
      "\n",
      "                     user_id  feedback               timestamp  \n",
      "0   6568cbef4a9658311b3ee704         0 2024-02-22 22:18:01.882  \n",
      "1   6568cbef4a9658311b3ee704         1 2024-02-22 22:17:04.611  \n",
      "2   6568cbef4a9658311b3ee704         1 2024-02-22 22:15:48.824  \n",
      "3   6568cbef4a9658311b3ee704         1 2024-02-22 22:16:06.681  \n",
      "4   6568cbef4a9658311b3ee704         1 2024-02-22 22:16:31.071  \n",
      "5   6568cbef4a9658311b3ee704         0 2024-02-22 22:16:10.772  \n",
      "6   6568cbef4a9658311b3ee704         1 2024-02-22 22:18:26.407  \n",
      "7   6568cbef4a9658311b3ee704         0 2024-02-22 22:02:52.570  \n",
      "8   6568cbef4a9658311b3ee704         1 2024-02-22 22:15:43.720  \n",
      "9   6568cbef4a9658311b3ee704         1 2024-02-22 22:18:14.322  \n",
      "10  6568cbef4a9658311b3ee704         1 2024-02-22 22:18:18.339  \n",
      "11  6568cbef4a9658311b3ee704         0 2024-02-22 22:15:55.262  \n",
      "12  6568cbef4a9658311b3ee704         1 2024-02-22 22:17:33.244  \n",
      "13  6568cbef4a9658311b3ee704         0 2024-02-22 22:16:38.485  \n",
      "14  6568cbef4a9658311b3ee704         0 2024-02-22 22:16:52.380  \n",
      "15  6568cbef4a9658311b3ee704         0 2024-02-22 22:16:28.882  \n",
      "16  6568cbef4a9658311b3ee704         0 2024-02-22 22:16:54.402  \n",
      "17  6568cbef4a9658311b3ee704         0 2024-02-22 22:17:40.504  \n",
      "18  6568cbef4a9658311b3ee704         0 2024-02-22 22:17:45.910  \n",
      "19  6568cbef4a9658311b3ee704         0 2024-02-22 22:17:11.479  \n",
      "20  6568cbef4a9658311b3ee704         0 2024-02-22 22:16:44.777  \n",
      "21  6568cbef4a9658311b3ee704         0 2024-02-22 22:15:52.110  \n",
      "22  6568cbef4a9658311b3ee704         0 2024-02-22 22:17:17.690  \n",
      "23  6568cbef4a9658311b3ee704         0 2024-02-22 22:17:09.415  \n",
      "24  6568cbef4a9658311b3ee704         0 2024-02-22 22:16:21.304  \n",
      "25  6568cbef4a9658311b3ee704         0 2024-02-22 22:17:56.558  \n",
      "26  6568cbef4a9658311b3ee704         1 2024-02-22 22:16:26.727  \n",
      "27  6568cbef4a9658311b3ee704         1 2024-02-22 22:18:05.948  \n",
      "28  6568cbef4a9658311b3ee704         0 2024-02-22 22:16:50.417  \n",
      "29  6568cbef4a9658311b3ee704         1 2024-02-22 22:18:21.300  \n",
      "30  6568cbef4a9658311b3ee704         1 2024-02-22 22:17:14.039  \n",
      "31  6568cbef4a9658311b3ee704         1 2024-02-22 22:17:58.831  \n",
      "32  6568cbef4a9658311b3ee704         1 2024-02-22 22:16:18.054  \n",
      "33  6568cbef4a9658311b3ee704         0 2024-02-22 22:17:20.385  \n",
      "34  6568cbef4a9658311b3ee704         0 2024-02-22 22:16:33.169  \n",
      "35  6568cbef4a9658311b3ee704         0 2024-02-22 22:17:54.097  \n",
      "36  6568cbef4a9658311b3ee704         0 2024-02-22 22:17:42.589  \n",
      "37  6568cbef4a9658311b3ee704         0 2024-02-22 22:18:23.079  \n",
      "38  6568cbef4a9658311b3ee704         0 2024-02-22 22:16:59.719  \n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "userdata ={\n",
    "  \"_id\": {\n",
    "    \"$oid\": \"6567dcefba91df16f20f718d\"\n",
    "  },\n",
    "  \"username\": \"john_doe\",\n",
    "  \"full_name\": \"John Doe\",\n",
    "  \"email\": \"john@example.com\",\n",
    "  \"age\": 30,\n",
    "  \"address\": {\n",
    "    \"street\": \"123 Main St\",\n",
    "    \"city\": \"Anytown\",\n",
    "    \"state\": \"CA\",\n",
    "    \"zip_code\": \"12345\",\n",
    "    \"country\": \"USA\"\n",
    "  }\n",
    "}\n",
    "\n",
    "uid = '6568cbef4a9658311b3ee704'\n",
    "\n",
    "\n",
    "connection_string = \"mongodb+srv://hangodb:hangodb@cluster0.phdgtft.mongodb.net/\"\n",
    "dbname = \"Hango\"\n",
    "collection_name = \"ratings\"\n",
    "\n",
    "client = MongoClient(connection_string)\n",
    "db = client[dbname]\n",
    "\n",
    "collection = db[collection_name]\n",
    "#reviewTable = pd.DataFrame()\n",
    "\n",
    "query = {'user_id': uid}\n",
    "\n",
    "review_table = list(collection.find(query))\n",
    "\n",
    "generated_reviews = pd.DataFrame(review_table)\n",
    "\n",
    "print(generated_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d9564af-9b07-4578-8bc8-4af9acf7b738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feedback        lat         lon  rating  rating_amount  pet_sitting  \\\n",
      "0         0  33.789649 -118.216220     3.9            484            0   \n",
      "1         1  33.766751 -118.194775     4.9            150            0   \n",
      "2         1  33.771852 -118.145571     4.7            467            0   \n",
      "3         1  33.811592 -118.115888     4.6             87            0   \n",
      "4         1  33.785604 -118.173414     4.6             38            0   \n",
      "\n",
      "   barre_classes  food  gluten-free  tobacco_shops  ...  trainers  \\\n",
      "0              0     1            0              0  ...         0   \n",
      "1              0     1            0              0  ...         0   \n",
      "2              0     1            0              0  ...         0   \n",
      "3              0     1            0              0  ...         0   \n",
      "4              0     0            0              0  ...         0   \n",
      "\n",
      "   videos_&_video_game_rental  diners  ramen  main_type_Drinks  \\\n",
      "0                           0       0      0                 0   \n",
      "1                           0       0      0                 1   \n",
      "2                           0       0      0                 1   \n",
      "3                           0       0      0                 1   \n",
      "4                           0       0      0                 0   \n",
      "\n",
      "   main_type_Entertainment  main_type_Food  main_type_Museum/Art  \\\n",
      "0                        0               1                     0   \n",
      "1                        0               0                     0   \n",
      "2                        0               0                     0   \n",
      "3                        0               0                     0   \n",
      "4                        0               0                     1   \n",
      "\n",
      "   main_type_Nature/Recreation  main_type_Nightlife  \n",
      "0                            0                    0  \n",
      "1                            0                    0  \n",
      "2                            0                    0  \n",
      "3                            0                    0  \n",
      "4                            0                    0  \n",
      "\n",
      "[5 rows x 367 columns]\n",
      "14313\n",
      "<bound method NDFrame.head of                       place_id                                           name  \\\n",
      "0     65c7c805d20df83fcf08aa6b                            The Great White Hut   \n",
      "1     65c7c805d20df83fcf08aa6c                                    Chick-fil-A   \n",
      "2     65c7c805d20df83fcf08aa6d             Melrose Food Co - by CloudKitchens   \n",
      "3     65c7c805d20df83fcf08aa6e                                      Taco Bell   \n",
      "4     65c7c805d20df83fcf08aa6f                               Grand Food Depot   \n",
      "...                        ...                                            ...   \n",
      "5049  65cbe9994d60dd8c13db5301                    Whitestone Restaurant & Bar   \n",
      "5050  65cbe9994d60dd8c13db5302                         The Shwack Beach Grill   \n",
      "5051  65cbe9994d60dd8c13db5303  The Original Patsy's Irish Pub, Laguna Niguel   \n",
      "5052  65cbe9994d60dd8c13db5306                     Scarlet Kitchen and Lounge   \n",
      "5053  65cbe9994d60dd8c13db5307                   El Cortez Mexican Restaurant   \n",
      "\n",
      "            lat         lon                                     address  \\\n",
      "0     34.150018 -118.256291              121 W California Ave, Glendale   \n",
      "1     34.049347 -118.259377              660 S Figueroa St, Los Angeles   \n",
      "2     34.082243 -118.309399              615 N Western Ave, Los Angeles   \n",
      "3     34.003267 -118.406905            4416 Sepulveda Blvd, Culver City   \n",
      "4     34.014740 -118.278774                  358 W 38th St, Los Angeles   \n",
      "...         ...         ...                                         ...   \n",
      "5049  33.467364 -117.695068  34212 Pacific Coast Hwy Unit A, Dana Point   \n",
      "5050  33.465381 -117.702025             24502 Del Prado Ave, Dana Point   \n",
      "5051  33.541835 -117.692479         28971 Golden Lantern, Laguna Niguel   \n",
      "5052  33.522121 -117.617840      30865 Gateway Pl, Rancho Mission Viejo   \n",
      "5053  33.542044 -117.692525    28971 Golden Lantern a101, Laguna Niguel   \n",
      "\n",
      "      rating  rating_amount age price  \\\n",
      "0        4.2            818   N     1   \n",
      "1        4.2           1840   N     1   \n",
      "2        4.5            133   N     2   \n",
      "3        3.9            618   N     1   \n",
      "4        4.6            258   N     2   \n",
      "...      ...            ...  ..   ...   \n",
      "5049     4.4            135   Y     3   \n",
      "5050     4.5           1447   Y     1   \n",
      "5051     4.3            451   Y     2   \n",
      "5052     4.1            109   Y     2   \n",
      "5053     4.3            397   Y     2   \n",
      "\n",
      "                                                weblink  ...  trainers  \\\n",
      "0     https://www.google.com/maps/place/?q=place_id:...  ...         0   \n",
      "1     https://www.google.com/maps/place/?q=place_id:...  ...         0   \n",
      "2     https://www.google.com/maps/place/?q=place_id:...  ...         0   \n",
      "3     https://www.google.com/maps/place/?q=place_id:...  ...         0   \n",
      "4     https://www.google.com/maps/place/?q=place_id:...  ...         0   \n",
      "...                                                 ...  ...       ...   \n",
      "5049  https://www.google.com/maps/place/?q=place_id:...  ...         0   \n",
      "5050  https://www.google.com/maps/place/?q=place_id:...  ...         0   \n",
      "5051  https://www.google.com/maps/place/?q=place_id:...  ...         0   \n",
      "5052  https://www.google.com/maps/place/?q=place_id:...  ...         0   \n",
      "5053  https://www.google.com/maps/place/?q=place_id:...  ...         0   \n",
      "\n",
      "      videos_&_video_game_rental  diners  ramen  main_type_Drinks  \\\n",
      "0                              0       0      0                 0   \n",
      "1                              0       0      0                 0   \n",
      "2                              0       0      0                 0   \n",
      "3                              0       0      0                 0   \n",
      "4                              0       0      0                 0   \n",
      "...                          ...     ...    ...               ...   \n",
      "5049                           0       0      0                 0   \n",
      "5050                           0       0      0                 0   \n",
      "5051                           0       0      0                 0   \n",
      "5052                           0       0      0                 0   \n",
      "5053                           0       0      0                 0   \n",
      "\n",
      "      main_type_Entertainment  main_type_Food  main_type_Museum/Art  \\\n",
      "0                           0               1                     0   \n",
      "1                           0               1                     0   \n",
      "2                           0               1                     0   \n",
      "3                           0               1                     0   \n",
      "4                           0               1                     0   \n",
      "...                       ...             ...                   ...   \n",
      "5049                        0               0                     0   \n",
      "5050                        0               0                     0   \n",
      "5051                        0               0                     0   \n",
      "5052                        0               0                     0   \n",
      "5053                        0               0                     0   \n",
      "\n",
      "      main_type_Nature/Recreation  main_type_Nightlife  \n",
      "0                               0                    0  \n",
      "1                               0                    0  \n",
      "2                               0                    0  \n",
      "3                               0                    0  \n",
      "4                               0                    0  \n",
      "...                           ...                  ...  \n",
      "5049                            0                    1  \n",
      "5050                            0                    1  \n",
      "5051                            0                    1  \n",
      "5052                            0                    1  \n",
      "5053                            0                    1  \n",
      "\n",
      "[5054 rows x 372 columns]>\n"
     ]
    }
   ],
   "source": [
    "#merge the two dataframes based on the place id to generate factor matrix\n",
    "#drop features that are irrelevant to the model (distinction)\n",
    "\n",
    "#merged_df related to the ratings\n",
    "\n",
    "merged_df = pd.merge(generated_reviews, place_df, left_on='place_id', right_on='place_id', how='inner')\n",
    "merged_df = merged_df.drop(columns=['_id','user_id','place_id','name', 'address', 'weblink','price','age','timestamp'])\n",
    "\n",
    "# Display the combined dataset\n",
    "print(merged_df.head())\n",
    "print(merged_df.size)\n",
    "\n",
    "print(place_df.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "228331d8-b567-4d36-8cd0-c46a1bd6c828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (31, 366) (31,)\n",
      "Test set shape: (8, 366) (8,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract features (X) and target variable (y)\n",
    "X = merged_df.drop(['feedback'], axis=1)\n",
    "y = merged_df['feedback']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b25a5916-b07a-457c-854a-805ef130b9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6741 - accuracy: 0.6250 - val_loss: 0.6681 - val_accuracy: 0.5714\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6256 - accuracy: 0.9583 - val_loss: 0.6478 - val_accuracy: 0.8571\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5890 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.8571\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5627 - accuracy: 0.9583 - val_loss: 0.6117 - val_accuracy: 0.8571\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5369 - accuracy: 0.9583 - val_loss: 0.5925 - val_accuracy: 0.8571\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5107 - accuracy: 0.9583 - val_loss: 0.5744 - val_accuracy: 0.8571\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4840 - accuracy: 0.9583 - val_loss: 0.5584 - val_accuracy: 0.8571\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4565 - accuracy: 0.9583 - val_loss: 0.5421 - val_accuracy: 0.8571\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4288 - accuracy: 0.9583 - val_loss: 0.5260 - val_accuracy: 0.8571\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4012 - accuracy: 0.9583 - val_loss: 0.5109 - val_accuracy: 0.8571\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3740 - accuracy: 0.9583 - val_loss: 0.4972 - val_accuracy: 0.8571\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3474 - accuracy: 0.9583 - val_loss: 0.4831 - val_accuracy: 0.8571\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3215 - accuracy: 0.9583 - val_loss: 0.4686 - val_accuracy: 0.8571\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2963 - accuracy: 0.9583 - val_loss: 0.4540 - val_accuracy: 0.8571\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2719 - accuracy: 0.9583 - val_loss: 0.4410 - val_accuracy: 0.8571\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2483 - accuracy: 0.9583 - val_loss: 0.4292 - val_accuracy: 0.8571\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2260 - accuracy: 0.9583 - val_loss: 0.4195 - val_accuracy: 0.8571\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2051 - accuracy: 0.9583 - val_loss: 0.4128 - val_accuracy: 0.8571\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1851 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.8571\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1665 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         3\n",
      "           1       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.80      0.80      0.75         8\n",
      "weighted avg       0.85      0.75      0.75         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Standardize features (optional but often recommended for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),  # Additional layer\n",
    "    tf.keras.layers.Dense(8, activation='relu'),   # Additional layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train_scaled, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "y_pred = np.round(y_pred_proba)\n",
    "\n",
    "# Convert predictions to binary (0 or 1)\n",
    "y_pred = y_pred.flatten().astype(int)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display additional metrics if needed\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be89f9de-4427-4989-9b13-097058a3a0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 1s 3ms/step\n",
      "                      place_id                              name  \\\n",
      "2509  65cbe827cbcec18078a36a9d                            Subway   \n",
      "3748  65cbe856cbcec18078a36f74                          Mollie's   \n",
      "3181  65cbe841cbcec18078a36d3d  Daniel's Bakery and Mexican Food   \n",
      "3090  65cbe83dcbcec18078a36ce2                    Bangkok Palace   \n",
      "3147  65cbe83fcbcec18078a36d1b                   Ice in Paradise   \n",
      "...                        ...                               ...   \n",
      "3456  65cbe84bcbcec18078a36e50                        The Bistro   \n",
      "3895  65cbe85ccbcec18078a37008                         Starbucks   \n",
      "3135  65cbe83fcbcec18078a36d0f                        McDonald's   \n",
      "2491  65cbe827cbcec18078a36a8b                   Jack in the Box   \n",
      "3093  65cbe83dcbcec18078a36ce5                      Tutti Frutti   \n",
      "\n",
      "      acceptance_probability  \n",
      "2509            1.274619e-06  \n",
      "3748            1.274187e-06  \n",
      "3181            1.273822e-06  \n",
      "3090            1.273064e-06  \n",
      "3147            1.265607e-06  \n",
      "...                      ...  \n",
      "3456            2.905894e-07  \n",
      "3895            2.863217e-07  \n",
      "3135            2.832535e-07  \n",
      "2491            2.497940e-07  \n",
      "3093            7.675545e-13  \n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#It would go here:\n",
    "\n",
    "# Drop unnecessary columns from place_df\n",
    "place_df_features = place_df.drop(columns=['address', 'weblink', 'price', 'age'])\n",
    "\n",
    "#STandardize here with drop\n",
    "# Standardize features\n",
    "place_df_features_scaled = scaler.transform(place_df_features.drop(columns=['place_id','name']))\n",
    "\n",
    "# Use the trained model to predict acceptance probabilities\n",
    "acceptance_probabilities = model.predict(place_df_features_scaled)\n",
    "\n",
    "# Add the predicted probabilities to place_df_features\n",
    "place_df_features['acceptance_probability'] = acceptance_probabilities\n",
    "\n",
    "# Sort by acceptance probability in descending order\n",
    "top_locations = place_df_features.sort_values(by='acceptance_probability', ascending=False)\n",
    "\n",
    "# Display the top locations\n",
    "print(top_locations[['place_id', 'name', 'acceptance_probability']].tail(500))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
